# 蜂鸟架构设计
<img src="https://github.com/user-attachments/assets/4b1b7516-3374-46ab-adb9-7530d2a283e4" alt="并行计算框架 Logo" style="zoom:50%;"/>  

## 一. 前言

​	写这个框架主要是为了深化自己对于并行计算框架的理解，对于原生Spark框架来说，Spark自己拥有优秀的批处理性能和在分布式架构下的通信功能，基于rdd的链式调用也非常优雅；对Flink框架来说，自身框架拥有优秀的容错能力，比如说checkpoint；有状态算子，内嵌的状态后端数据库等等，为流式计算带来很大的便利。在这里只是仿照它们实现了核心计算模型，并不具有真正的高性能，仅仅是一个并行计算的小型模型，加入了自己对于并行计算的理解。

​	在这里浅提一下之前有做过的一些工作：

​	由于之前也是在做数开相关的一些工作，会大量接触到大数据处理的一些框架。比如说，在`Spark`和`Flink`等框架中，已经实现了有关并行计算的逻辑。并且，在`Spark`引擎中，实现了相关异步算子，之前有遇到过IO密集型任务，整个任务的执行时间中，几乎1/3 或者 2/3 的时间都在用于读取数据，非常耗时，当时采用的是`Spark SQL`读取`Hive`中的数据，`Hive`自己有对于读取数据方面的一些优化，不过从算子的角度来说，`Spark`实际上有自己的异步算子，比如说`asyncCount`，异步收集数据量，但是在最后获取结果的时候会进行等待，可以在特殊场景下调用，但是，这个优化是比较有限的，但如果在数据量极高的场景下，可以采用，会有一点点的提升，更多的建议对代码进行优化，之前采用的手段主要是采用异步，并行流等等的方式优化。

### 1. 并行流：

​	使用并行流优化代码，这样代码在串行执行的时候，工作效率必定是不高的：

```java
for (int i = 0; i < 10; i++) {
  System.out.println("hello world")
}
```

​	这个就是典型的串行场景，如果改成：

```java
List<Integer> nums = new ArrayList<Integer>();
nums.addAll(Arrays.asList(1,2,3,4,5,6,7,8,9,10))
nums.parallelStream().forEach(System.out::println())
```

​	基于并行流的流式API来调用，就要比串行好一些，在数据量不多的场景下，大概能提升 25% 的效率。当然，这也只是小部分的优化，并且，基于并行流的场景一定是不能够改变最终结果的，否则优化就白做了。再比如说，我基于一定的规则，循环判断某些任务是否符合条件，不符合条件的不予提交，这也是一样的，使用并行流进行过滤就是一个很好的方式。

### 2. 异步

​	在这里浅说一下之前异步任务运行的场景，如果只是简单的报表场景，使用SQL的效率是一定要比Spark中进行广播链接的效率要高的，如果使用Spark的原生框架，那么需要自己去判断用什么分区器比较合适，或者采用什么合并策略，但是在SQL中，这些优化手段都是比较成熟的，比如说，现在我要读取50w行的数据，和小表进行广播连接，那么用SQL落一张临时表要比Spark中读取连接效率高得多，Spark执行40min都执行不完的任务，在SQL中可能3min就执行完毕了。当然，这需要先落一张临时表进行join，但是比起效率的提升，临时表占用的空间可以说是不算什么的。

​	异步的场景，比如说我利用Spark读取Hudi中的数据，需要写出到外部系统，那么我先利用SQL把数据读出来，利用Spark进行加工处理后发送到外部服务器的时候就可以很好地利用异步来完成。开一个线程池，然后利用异步调用客户端，让线程去进行成批发送，一旦发送后，不等结果，立马返回，调用结果之后再返回，可以极大地减轻过程中的阻塞问题。不过这么做也还有一个前提，就是Spark中的核心如果不多的话，就不要开这么多线程了，线程之间上下文切换也是需要一定时间的，包括这些线程也会和Spark的线程争抢CPU资源，需要平衡速率和资源的影响。

### 3. 分区算子

​	在这里再重新提一下forEachPartition算子，这个算子底层实际上调用的就是mapPartition算子，mapPartition算子会根据实际分区来创建任务，也就是并行计算，如果使用collectAsList算子，调用之后会将所有结果统一收集起来返回Driver端造成很大的压力，那么为了适应输出到外部系统的场景，那么就可以利用这个分区算子，将数据并行计算，不要将数据收集到Driver端进行统一处理，应该放到各个Executor端进行处理，利用并行计算的优势处理任务，同样地，这种方式适合计算密集型任务，如果是IO密集型任务，需要采用相应的异步策略进行处理。

​	如果我们将数据都分散到Executor端进行处理，极大减轻了Driver端的压力，这个当然是很好的，但是这给调试带来了一定的压力，如果分散到各个Executor端，如果需要查看任务日志，就需要在每个Executor端查看它们的日志，而且这个报错是不会影响到Driver端的，顶多在Driver端会报出线程相关的错误，很难通过Driver端的日志看到什么，所以就需要一个方法去方便地调试，后续我采用了Accumulator接口，当每一批次的第一条数据发送成功后，将第一条数据收集到累加器中，这个累加器会作为全局累加器持续收集，知道任务完成，这样，不会对Driver端造成过大的压力，同时进行并行计算，调试也比较方便，只需要查看日志中累加器模块是否有值即可，如果有值，那么说明本批次发送成功，同时也可以查看每一批次的序号是否连续，如果连续，说明各个批次的发送极大可能是没有问题的，如果不连续，说明某一批次的数据出了问题，这时候再去翻每一个Executor端的日志即可。

## 二.  Spark任务提交流程

​	在Spark任务提交的过程中，首先是解析用户传入的命令行参数：

```shell
[root@192.168.222.130]# spark-submit \
  --class com.example.YourApp \
  --master yarn \
  --deploy-mode cluster \
  --executor-memory 4G \
  --num-executors 10 \
  --executor-cores 2 \
  /code/spark_test.jar \
  arg1 arg2  
```

​	然后会有一个SparkSubmit类去解析用户传入的命令行参数，然后运行jvm命令开始解析jar包并执行。

​	这时候开始初始化Spark的环境变量也就是SparkContext，初始化SparkContext的时候，会解析用户传入的命令行参数，也就是SparkConf，这时候，开始初始化三个类，也就是SchedulerBackend，TaskScheduler，DAGScheduler；Scheduler启动的时候则会初始化两个进程，这里SchedulerBackend在初始化的时候会创建两个对象，也就是ClientActor和DriverActor，这两个对象会分别负责向master注册用户提交的任务，接受executor的注册，同时向executor传递需要执行的任务。

​	当master接收到DriverActor提交的任务请求时，会将这个任务的请求参数进行解析，封装为ApplicationInfo对象，

​	
